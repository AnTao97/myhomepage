<!DOCTYPE html>
<html><head>
<title>An Tao's Homepage</title>
<link rel="icon" href="image/icon.jpg" >

<script type="text/javascript">
      //判断是否手机访问 如果是跳转 
      try {
      var urlhash = window.location.hash;
      if (!urlhash.match("fromapp")) {
      if ((navigator.userAgent.match(/(iPhone|iPod|Android|ios|iPad)/i))) {
      window.location = "/mobile.html";
      }
      }
      } catch (err) {}
</script>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css">
<style type="text/css">

body
{
 	font-family: 'Lucida Grande',Arial,Helvetica,'STXihei',sans-serif; 
    background-color : #fff;
    font-size: 18px;
    width : 1440px;
}
    .content
	{
    		width : 1100px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		margin-left: 260px;
/*     		background-color : #fff;
    		box-shadow: 0px 0px 10px #999; */
/*     		border-radius: 15px;  */
	}	
	table
	{
		padding: 5px;
	}
	
  	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 990px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 980px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		/*color: #1367a7;*/
		height: 158px;
/*     		font-size:110%; */
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h1
	{
		font-size:210%;
	}
	h2
	{
		font-size:150%;
	}
	h3
	{
		font-size:120%;
	}
	h4
	{
		font-size:110%;
	}
	p
	{
/*		color: #5B5B5B;*/
		margin-bottom: 10px;
		/*margin-left: 20px;*/
		text-indent:2em;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover
	{
		text-decoration:underline;
		color: #C20C0C;
	}

    #tsinghua_logo {
        position: absolute;
        left: 646px;
        top: 28px;
        width: 200px;
        height: 20px;
    }
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        /*-moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;*/
        /*box-shadow: 3px 3px 6px #888;*/
    }


underline {
	border-bottom: 2px solid;
	display:inline-block;
}

</style>

<script type="text/javascript" language="javascript">
	function addEventHandler(target, type, func){
	if (target.addEventListener)
	target.addEventListener(type, func, false);
	else if (target.attachEvent)
	target.attachEvent("on" + type, func);
	else target["on" + type] = func;
	}
	var advIniTop = 0;
	function move(){
	var layer1 = document.getElementById("nav1");
	if (layer1) layer1.style.top = advIniTop + document.body.scrollTop || document.documentElement.scrollTop + 10 + "px";
	}
	addEventHandler(window, "scroll", move);
</script>

</head>
<a name="home"></a>
<body>
<div id="nav1" style="position:absolute;z-index:10;top:10px;left:100px;width:200px;height:500px">
	<table>
	  <td style="height:68px">
	  </td>
	</table>
	<h2>Index</h2>
	<table>
	  <td style="height:15px">
	  </td>
	</table>
	<div style="position:absolute;z-index:10;left:2px;border-left:2px solid #3B3B3B">
	<table>
	  <td style="width:15px">
	  </td>
	  <td valign="middle">
	    <h4>
			<a href="#home" style="color: #3B3B3B">Home</a><br><br>
			<a href="#about-me" style="color: #3B3B3B">About Me</a><br><br>
			<a href="#publications" style="color: #3B3B3B">Publications</a><br><br>
			<a href="#education" style="color: #3B3B3B">Education</a><br><br>
			<a href="#honors" style="color: #3B3B3B">Honors</a><br><br>
			<a href="#activities" style="color: #3B3B3B">Activities</a><br><br>
			<a href="#misc" style="color: #3B3B3B">Misc Facts</a><br><br>
			<a href="#contact" style="color: #3B3B3B">Contact</a><br><br>
			<a href="index_cn.html" style="color: #3B3B3B">[中文版]</a>
		</h4>
	  </td>
	</table></div><br><br>
</div>
<br>
<div class="content">
	<div id="container">
	<table>
	<tbody><tr>
	<td style="width:520px">
    <img id="myPicture" src="image/An_Tao.jpg" 
	 style="float:center; border-radius: 15px"
	 height="300px">
  	</td>
	<td>
	<div id="DocInfo">
	<br><h1>An Tao</h1><br>
	<h4>Ph.D. Student, Tsinghua University</h4>
	<table>
	  <td style="height:20px">
	  </td>
	</table>
	<font size=4.5><a href="https://scholar.google.com/citations?user=0FyWZPMAAAAJ&hl=en">Google Scholar</a> | <a href="https://github.com/antao97">GitHub</a></font>
	</div>
	</td>
	</tr>
	</tbody></table>

	<a name="about-me"></a><br><br><br>
	<h2>About Me</h2><br>
	<p>
	I am a fifth year Ph.D. candidate in <a href="http://ivg.au.tsinghua.edu.cn/index.php">i-VisionGroup</a> of the <a href="http://www.au.tsinghua.edu.cn">Department of Automation</a> at <a href="https://www.tsinghua.edu.cn/publish/thu2018en/index.html">Tsinghua University</a>, advised by Prof. <a href="https://scholar.google.com.hk/citations?user=6a79aPwAAAAJ&hl=zh-CN">Jie Zhou</a>, Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>, and Prof. <a href="https://duanyueqi.github.io/">Yueqi Duan</a>. 
	Prior to joining Tsinghua, I got my B.Eng. from <a href="http://www.seu.edu.cn/english/main.html">Southeast University</a>. </p>
	<p>
	My research focuses on 3D computer vision, mainly 3D scene understanding.
	</p>
	
    <br><br><br>
    <h2>News</h2><br>
    <!-- &nbsp&nbsp&nbsp&nbsp<font style="color: #DD0000">The old url (www.antao.site) of my homepage is about to expire. You can save my new url: <a href="https://antao97.github.io">antao97.github.io</a></font> -->
    <ul>
    	<p><li><b>[2022.10.17]</b> Our journal version of <a href="https://arxiv.org/abs/2210.08159">Dynamics-aware Attack</a> is on arXiv!</li></p>
    	<p><li><b>[2022.07.01]</b> Our <a href="https://arxiv.org/abs/2012.10217">SegGroup</a> is accepted by TIP!</li></p>
    	<p><li><b>[2021.12.20]</b> Our <a href="https://arxiv.org/abs/2112.09428">Dynamics-aware Attack</a> is on arXiv!</li></p>
    	<p><li><b>[2021.11.19]</b> I pass the Ph.D. qualifying exam and become a Ph.D. candidate!</li></p>
        <p><li><b>[2020.12.18]</b> Our <a href="https://arxiv.org/abs/2012.10217">SegGroup</a> is on arXiv!</li></p>
    </ul>
    <table>
	  <td style="height:20px">
	  </td>
	</table>

    <!-- <h2>Updates</h2>
    <ul>
        <li>[2019/02/25] 3 papers are accepted by <a href="http://cvpr2019.thecvf.com/">CVPR'19</a>!</li>
        <li>[2018/10/09] I am honored with the National Scholarship of Tsinghua University.</li>
        <li>[2018/08/20] I give a talk on <a href="ICPR18_metric.pdf"> Deep Metric Learning for Pattern Recognition</a> at the <a href="http://www.icpr2018.org/index.php?m=content&c=index&a=show&catid=47&id=2">Tutorial of ICPR'18</a>.
        <li>[2018/07/26] I am honored with the Outstanding Reviewer Award of <a href="http://www.icme2018.org/">ICME'18</a>.</li>
        <li>[2018/07/17] 1 paper is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34#">TPAMI</a>!</li>
        <li>[2018/07/03] 1 paper is accepted by <a href="https://eccv2018.org/">ECCV'18</a>!</li>
        <li>[2018/05/15] I give a talk on <a href="FG18_face.pdf">Representation Learning for Face Alignment and Recognition</a> at the <a href="https://fg2018.cse.sc.edu/tutorial.html">Tutorial of FG'18</a>.
        <li>[2018/02/28] 2 papers are accepted by <a href="http://cvpr2018.thecvf.com/">CVPR'18</a>!</li>
        <li>[2017/10/10] I am honored with the National Scholarship of Tsinghua University.</li>
        <li>[2017/05/25] 1 paper is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34#">TPAMI</a>!</li>
        <li>[2017/03/03] 1 paper is accepted by <a href="http://cvpr2017.thecvf.com/">CVPR'17</a>!</li>
        <li>[2017/02/27] 1 paper is accepted by <a href="http://www.icme2017.org/">ICME'17</a>!</li>
        </ul> -->




  <!-- <h2>Selected Publications</h2>
	<table class="pub_table" >
	<tbody> 
        <tr>
           <td class="pub_td1"><img src="image/cluster_img.bmp" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Jiwen Lu, Ziwei Wang, Jianjiang Feng, and Jie Zhou<br><strong>Learning Deep Binary Descriptor with Multi-Quantization.</strong><br><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2018, accepted.<br>[<a href="TPAMI18_Learning Deep Binary Descriptor with Multi-Quantization.pdf">PDF</a>]
         </td>
        </tr>

        <tr>
           <td class="pub_td1"><img src="image/calbfl_flowchart.bmp" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Jiwen Lu, Jianjiang Feng, and Jie Zhou<br><strong>Context-Aware Local Binary Feature Learning for Face Recognition.</strong><br><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, vol. 40, no. 5, pp. 1139-1153, 2018.<br>[<a href="TPAMI18_Context-Aware Local Binary Feature Learning for Face Recognition.pdf">PDF</a>][<a href="https://github.com/duanyq14/CA-LBFL/">Code</a>]
         </td>
        </tr>

        <tr>
           <td class="pub_td1"><img src="image/dlml_flowchart.bmp" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Jiwen Lu, Jianjiang Feng, and Jie Zhou<br><strong>Deep Localized Metric Learning.</strong><br><i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</i>, 2018, accepted.<br>[<a href="TCSVT18_Deep Localized Metric Learning.pdf">PDF</a>]
         </td>
        </tr>

        <tr>
           <td class="pub_td1"><img src="image/occluded.jpg" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Jiwen Lu, Jianjiang Feng, and Jie Zhou<br><strong>Topology-Preserving Structural Matching for Automatic Partial Face Recognition.</strong><br><i>IEEE Transactions on Information Forensics and Security (TIFS)</i>, vol. 13, no. 7, pp. 1823-1837, 2018.<br>[<a href="TIFS18_Topology-Preserving Structural Matching for Automatic Partial Face Recognition.pdf">PDF</a>]
         </td>
        </tr>        

        <tr>
           <td class="pub_td1"><img src="image/aml.bmp" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Wenzhao Zheng, Xudong Lin, Jiwen Lu, and Jie Zhou<br><strong>Deep Adversarial Metric Learning.</strong><br><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, pp. 2780-2789, 2018, as <b>spotlight</b>.<br>[<a href="CVPR18_Deep Adversarial Metric Learning.pdf">PDF</a>][<a href="DAML_slides.pdf">Slides</a>][<a href="DAML_poster.pdf">Poster</a>][<a href="https://github.com/duanyq14/daml/">Code</a>]
         </td>
        </tr>

        <tr>
           <td class="pub_td1"><img src="image/reliability.bmp" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Ziwei Wang, Jiwen Lu, Xudong Lin, and Jie Zhou<br><strong>GraphBit: Bitwise Interaction Mining via Deep Reinforcement Learning.</strong><br><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, pp. 8270-8279, 2018.<br>[<a href="CVPR18_GraphBit Bitwise Interaction Mining via Deep Reinforcement Learning.pdf">PDF</a>][<a href="GraphBit_poster.pdf">Poster</a>][<a href="https://github.com/duanyq14/graphbit/">Code</a>]
         </td>
        </tr>

        <tr>
           <td class="pub_td1"><img src="image/dvml_flowchart.png" class="papericon"></td>
           <td class="pub_td2">Xudong Lin, <u>Yueqi Duan</u>, Qiyuan Dong, Jiwen Lu, and Jie Zhou<br><strong>Deep Variational Metric Learning.</strong><br><i>European Conference on Computer Vision (ECCV)</i>, 2018, accepted.<br>[<a href="ECCV18_Deep Variational Metric Learning.pdf">PDF</a>]
           </td>
        </tr>

        <tr>
           <td class="pub_td1"><img src="image/rilbd_flowchart.bmp" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Jiwen Lu, Jianjiang Feng, and Jie Zhou<br><strong>Learning Rotation-Invariant Local Binary Descriptor.</strong><br><i>IEEE Transactions on Image Processing (TIP)</i>, vol. 26, no. 8, pp. 3636-3651, 2017.<br>[<a href="TIP17_Learning Rotation-Invariant Local Binary Descriptor.pdf">PDF</a>]
         </td>
        </tr>

        <tr>
           <td class="pub_td1"><img src="image/binarization.bmp" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Jiwen Lu, Ziwei Wang, Jianjiang Feng, and Jie Zhou<br><strong>Learning Deep Binary Descriptor with Multi-Quantization.</strong><br><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, pp. 4857-4866, 2017.<br>[<a href="CVPR17_Learning Deep Binary Descriptor with Multi-Quantization.pdf">PDF</a>][<a href="dbdmq_poster.pdf">Poster</a>]
         </td>
        </tr>

        <tr>
           <td class="pub_td1"><img src="image/tpgm_flowchart.png" class="papericon"></td>
           <td class="pub_td2"><u>Yueqi Duan</u>, Jiwen Lu, Jianjiang Feng, and Jie Zhou<br><strong>Topology Preserving Graph Matching for Partial Face Recognition.</strong><br><i>IEEE International Conference on Multimedia and Expo (ICME)</i>, pp. 1494-1499, 2017, as <b>oral</b>.<br>[<a href="ICME17_Topology Preserving Graph Matching for Partial Face Recognition.pdf">PDF</a>][<a href="TPGM_slides.pdf">Slides</a>]
         </td>
        </tr> -->

  <a name="publications"></a><br><br><br>
  <h2>Selected Publications</h2><br>
  	<table>
	  <td style="height:10px">
	  </td>
	</table>

	<table>
	  <tbody><tr>
	  <td style="width:230px; height:220px" valign="middle" align='middle'>
	  	<table>
		  <td style="height:15px">
		  </td>
		</table>
	    <img src="image/attack.png" height="210px">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>Dynamics-aware Adversarial Attack of Adaptive Neural Networks</b><br>
	    	<u>An Tao</u>, <a href="https://duanyueqi.github.io/">Yueqi Duan</a>, <a href="https://github.com/HilbertWang2002">Yingqi Wang</a>, <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>, and <a href="https://scholar.google.com.hk/citations?user=6a79aPwAAAAJ&hl=zh-CN">Jie Zhou</a><br>
	    	<i>arXiv preprint</i><br>
	    	<font size=3>[<a href="https://arxiv.org/abs/2210.08159">arXiv</a>] [<a href="https://github.com/antao97/LGM">Code</a>] [<a href="https://arxiv.org/abs/2112.09428">Conference Version</a>]
	    	<br>
	    	<table>
			  <td style="height:10px">
			  </td>
			</table>
	    	Most existing adversarial attack algorithms are designed under a basic assumption -- the network architecture is fixed throughout the attack process. However, this assumption does not hold for many recently proposed adaptive neural networks, which adaptively deactivate unnecessary execution units based on inputs to improve computational efficiency. </font>
	    </div>
	</tr></tbody>
	</table>
	<table>
	  <td style="height:35px">
	  </td>
	</table>

  	<table>
	  <tbody><tr>
	  <td style="width:230px; height:210px" valign="middle" align='middle'>
	    <img src="image/seggroup.png" height="190px">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>SegGroup: Seg-Level Supervision for 3D Instance and Semantic Segmentation</b><br>
	    	<u>An Tao</u>, <a href="https://duanyueqi.github.io/">Yueqi Duan</a>, <a href="https://weiyithu.github.io/">Yi Wei</a>, <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>, and <a href="https://scholar.google.com.hk/citations?user=6a79aPwAAAAJ&hl=zh-CN">Jie Zhou</a><br>
	    	<i>IEEE Transactions on Image Processing (<b>TIP</b>), 2022</i><br>
	    	<font size=3>[<a href="https://arxiv.org/abs/2012.10217">arXiv</a>] [<a href="https://github.com/antao97/SegGroup">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/536482202">Zhihu</a>] [<a href="https://github.com/antao97/SegGroup/blob/main/FAQ.md">FAQ</a>]
	    	<br>
	    	<table>
			  <td style="height:10px">
			  </td>
			</table>
	    	By fully taking the advantages of locations, we design a weakly supervised point cloud segmentation algorithm that only requires clicking on one point per instance to indicate its location for annotation. </font>
	    </div>
	</tr></tbody>
	</table>
	<table>
	  <td style="height:35px">
	  </td>
	</table>

	<table>
	  <td style="width:30px">
	  </td>
	  <td>
	  	<h4>>> <a href="paper/index.html">Full Publication List</a></h4>
	  </td>
	</table>


  <a name="education"></a><br><br><br>
  <h2>Education</h2><br>
  
	  <table>
	  <tbody><tr>
	  <td style="width:20px">
	  </td>
	  <td style="width:110px; height:110px" valign="middle">
	    <a href="https://www.tsinghua.edu.cn/publish/thu2018en/index.html"><img src="image/tsinghua.png" height="100px"></a>
	  </td>
	  <td style="width:30px">
	  </td>
	  <td valign="middle">
	    <div>
	    Ph.D. Degree, Department of Automation, Tsinghua University, China.<br>
	    2019.8 - Present
	    </ul>
	    </div>
	  </td>
	  </tr></tbody>
	  </table><br>

	  <table>
	  <tbody><tr>
	  <td style="width:20px">
	  </td>
	  <td style="width:110px; height:110px" valign="middle">
	    <a href="http://www.seu.edu.cn/english/main.html"><img src="image/seu.jpg" height="100px"></a>
	  </td>
	  <td style="width:30px">
	  </td>
	  <td valign="middle">
	    <div>
	    B.Eng. Degree, School of Information Science and Engineering, Southeast University, China.<br>
		2015.8 - 2019.6
	    </ul>
	    </div>
	  </td>
	  </tr></tbody>
	  </table>
	  <table>
	    <td style="height:20px">
	    </td>
	  </table>

    <a name="honors"></a><br><br><br>
    <h2>Honors</h2><br>
        <ul>
            <p><li>&nbsp; Outstanding Graduate of Southeast University, 2019</li></p>
	    	<p><li>&nbsp; Merit Student of Southeast University, 2016, 2017 & 2018</li></p>
            <p><li>&nbsp; President Scholarship of Southeast University, 2016</li></p>
            <p><li>&nbsp; Mayor's Award of Beijing in Technical Innovation, 2015</li></p>
            <p><li>&nbsp; First Prize in the Awarding Program for Future Scientists, 2014</li></p>
         </ul>

    <a name="activities"></a><br><br><br>
    <h2>Professional Activities</h2><br>
    	<table>
	    <tbody><tr>
	    <td style="width:15px">
	    </td>
	    <td valign="middle">
	      <div>
	      <h3>Conference Reviewer: </h3>
	      </div>
	    </td>
	    </tr></tbody>
	    </table>
        <ul>
            <p><li>&nbsp; IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021/2022/2023</li></p>
            <p><li>&nbsp; IEEE/CVF International Conference on Computer Vision (ICCV), 2021/2023</li></p>
            <p><li>&nbsp; European Conference on Computer Vision (ECCV), 2022</li></p>
            <p><li>&nbsp; IEEE International Conference on Multimedia and Expo (ICME), 2021/2022/2023</li></p>
            <p><li>&nbsp; IEEE International Conference on 3D Vision (3DV), 2022</li></p>
            <p><li>&nbsp; IEEE International Conference on Image Processing (ICIP), 2022/2023</li></p>
            <p><li>&nbsp; IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2023</li></p>
         </ul>


<!--     <h2>Professional Activities</h2>
        <ul>
            <li><b>Reviewer</b>, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018-.</li>
            <li><b>Reviewer</b>, IEEE Transactions on Image Processing, 2017-.</li>
            <li><b>Reviewer</b>, IEEE Transactions on Circuits and Systems for Video Technology, 2017-.</li>
            <li><b>Reviewer</b>, IEEE Transactions on Information Forensics and Security, 2018-.</li>
            <li><b>Reviewer</b>, IEEE Transactions on Biometrics, Behavior, and Identity Science, 2018-.</li>
            <li><b>Reviewer</b>, IEEE Access, 2018-.</li>
            <li><b>Reviewer</b>, Pattern Recognition, 2016-.</li>
            <li><b>Reviewer</b>, Journal of Visual Communication and Image Representation, 2017-.</li>
            <li><b>Reviewer</b>, International Journal of Machine Learning and Cybernetics, 2018-.</li>
            <li><b>Reviewer</b>, Multimedia Systems, 2018-.</li>
            <li><b>Reviewer</b>, IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019.</li>
            <li><b>Reviewer</b>, IEEE International Conference on Computer Vision, 2019.</li>
            <li><b>Reviewer</b>, IEEE International Conference on Multimedia and Expo, 2018.</li>
            <li><b>Reviewer</b>, IEEE International Conference on Image Processing, 2017-2018.</li>
        </ul>   -->  
   
  	
	<a name="misc"></a><br><br><br>
	<h2>Miscellaneous Facts</h2><br>
		<p>I admire a famous quote from <a href="https://en.wikipedia.org/wiki/Zhang_Zai">Zhang Zai</a>: To set conscience for our world, to secure life and fortune for all people, to continue teachings of past sages, and to establish peace for all future generations.</p>
		<p>Now I mainly focus on my research and work hard to publish more papers.</p>


	<a name="contact"></a><br><br><br>
	<h2>Contact</h2><br>
	<table>
    <tbody><tr>
    <td style="width:15px">
    </td>
    <td valign="middle">
      <div>
      Email: ta19@mails.tsinghua.edu.cn<p></p>
      Address: Room 624, Central Main building, Tsinghua University, Beijing
      </div>
    </td>
    </tr></tbody>
    </table>

</div>
</div>
<br>
<center><font size=3 style="color: #3B3B3B">—&nbsp;&nbsp; Last updated: Sep, 2023 &nbsp;&nbsp;—</font></center><br>
<center><font size=2 style="color: #BBBBBB">Copyright &copy 2023 An Tao. All Rights Reserved.</font></center><br>
</body></html>
